{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxjh2cPw-l1a"
      },
      "source": [
        "# download and import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkLM8YnJHunz",
        "outputId": "164863da-5a79-45f0-b6ed-0cd58b9ef7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.7/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j0iGfC57wQvy"
      },
      "outputs": [],
      "source": [
        "#load the modules for data preprocess\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from google.colab import drive\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXJMY6J0wjGT",
        "outputId": "7bee04af-39fc-4371-edc3-eecd84aa839e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#connect with google drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the images you are processing\n",
        "#it could be others folders as well\n",
        "!unzip /content/drive/MyDrive/CBIS-DDSM/roi_crop_train.zip"
      ],
      "metadata": {
        "id": "LFROCt4cQKme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define how to name the converted images"
      ],
      "metadata": {
        "id": "0VvN39brdKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/CBIS-DDSM/mass_case_description_train_set.csv')\n",
        "\n",
        "test = pd.read_csv('/content/drive/MyDrive/CBIS-DDSM/mass_case_description_test_set.csv')"
      ],
      "metadata": {
        "id": "8cjTutG0j5Gx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_need = train[['patient_id', 'pathology', 'image file path', 'cropped image file path', 'ROI mask file path']]\n",
        "test_need = test[['patient_id', 'pathology', 'image file path', 'cropped image file path','ROI mask file path']]"
      ],
      "metadata": {
        "id": "KAZYek6HCdCb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([train_need, test_need], axis=0)"
      ],
      "metadata": {
        "id": "FPSMNXloDCpK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "mcGGkvhwVDnd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "DNC21g2uHKcR",
        "outputId": "0c80a33f-6839-4b33-c2f0-e4e2301a2b8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  patient_id  pathology                                    image file path  \\\n",
              "0    P_00001  MALIGNANT  Mass-Training_P_00001_LEFT_CC/1.3.6.1.4.1.9590...   \n",
              "1    P_00001  MALIGNANT  Mass-Training_P_00001_LEFT_MLO/1.3.6.1.4.1.959...   \n",
              "\n",
              "                             cropped image file path  \\\n",
              "0  Mass-Training_P_00001_LEFT_CC_1/1.3.6.1.4.1.95...   \n",
              "1  Mass-Training_P_00001_LEFT_MLO_1/1.3.6.1.4.1.9...   \n",
              "\n",
              "                                  ROI mask file path  \\\n",
              "0  Mass-Training_P_00001_LEFT_CC_1/1.3.6.1.4.1.95...   \n",
              "1  Mass-Training_P_00001_LEFT_MLO_1/1.3.6.1.4.1.9...   \n",
              "\n",
              "                            crop_-1                            ROI_-1  \\\n",
              "0   Mass-Training_P_00001_LEFT_CC_1   Mass-Training_P_00001_LEFT_CC_1   \n",
              "1  Mass-Training_P_00001_LEFT_MLO_1  Mass-Training_P_00001_LEFT_MLO_1   \n",
              "\n",
              "                          full_-1  \n",
              "0   Mass-Training_P_00001_LEFT_CC  \n",
              "1  Mass-Training_P_00001_LEFT_MLO  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46e3887d-496b-409f-9e90-b159c5587f25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>pathology</th>\n",
              "      <th>image file path</th>\n",
              "      <th>cropped image file path</th>\n",
              "      <th>ROI mask file path</th>\n",
              "      <th>crop_-1</th>\n",
              "      <th>ROI_-1</th>\n",
              "      <th>full_-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P_00001</td>\n",
              "      <td>MALIGNANT</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC/1.3.6.1.4.1.9590...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC_1/1.3.6.1.4.1.95...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC_1/1.3.6.1.4.1.95...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC_1</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC_1</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_CC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P_00001</td>\n",
              "      <td>MALIGNANT</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO/1.3.6.1.4.1.959...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO_1/1.3.6.1.4.1.9...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO_1/1.3.6.1.4.1.9...</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO_1</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO_1</td>\n",
              "      <td>Mass-Training_P_00001_LEFT_MLO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e3887d-496b-409f-9e90-b159c5587f25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46e3887d-496b-409f-9e90-b159c5587f25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46e3887d-496b-409f-9e90-b159c5587f25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9feef70c-2169-48c7-be6e-6e5436679666\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9feef70c-2169-48c7-be6e-6e5436679666')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9feef70c-2169-48c7-be6e-6e5436679666 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 1696,\n  \"fields\": [\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 892,\n        \"samples\": [\n          \"P_00173\",\n          \"P_01238\",\n          \"P_01447\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pathology\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MALIGNANT\",\n          \"BENIGN\",\n          \"BENIGN_WITHOUT_CALLBACK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image file path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1592,\n        \"samples\": [\n          \"Mass-Training_P_01426_RIGHT_CC/1.3.6.1.4.1.9590.100.1.2.223698696711150153306218170170376403743/1.3.6.1.4.1.9590.100.1.2.379056257212874666818466899260789254386/000000.dcm\",\n          \"Mass-Training_P_01803_RIGHT_CC/1.3.6.1.4.1.9590.100.1.2.407718718913705537725964228401538328334/1.3.6.1.4.1.9590.100.1.2.284762492511939117113096431964067150055/000000.dcm\",\n          \"Mass-Test_P_01365_LEFT_CC/1.3.6.1.4.1.9590.100.1.2.407309539912295400320902979953166338001/1.3.6.1.4.1.9590.100.1.2.190178845412089478108126327520309953929/000000.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cropped image file path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1696,\n        \"samples\": [\n          \"Mass-Training_P_00889_LEFT_MLO_1/1.3.6.1.4.1.9590.100.1.2.35139905110871569019580581361824737195/1.3.6.1.4.1.9590.100.1.2.344919126411162871929480697862514268877/000000.dcm\",\n          \"Mass-Training_P_00148_RIGHT_MLO_1/1.3.6.1.4.1.9590.100.1.2.158214612311951785314328526103871080342/1.3.6.1.4.1.9590.100.1.2.325678795912867694418543446014194692233/000000.dcm\",\n          \"Mass-Training_P_00199_LEFT_MLO_1/1.3.6.1.4.1.9590.100.1.2.147654901612053919533722697530855031646/1.3.6.1.4.1.9590.100.1.2.375750281512821445331731529121143204781/000000.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROI mask file path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1696,\n        \"samples\": [\n          \"Mass-Training_P_00889_LEFT_MLO_1/1.3.6.1.4.1.9590.100.1.2.35139905110871569019580581361824737195/1.3.6.1.4.1.9590.100.1.2.344919126411162871929480697862514268877/000001.dcm\\n\",\n          \"Mass-Training_P_00148_RIGHT_MLO_1/1.3.6.1.4.1.9590.100.1.2.158214612311951785314328526103871080342/1.3.6.1.4.1.9590.100.1.2.325678795912867694418543446014194692233/000001.dcm\\n\",\n          \"Mass-Training_P_00199_LEFT_MLO_1/1.3.6.1.4.1.9590.100.1.2.147654901612053919533722697530855031646/1.3.6.1.4.1.9590.100.1.2.375750281512821445331731529121143204781/000001.dcm\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_-1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1696,\n        \"samples\": [\n          \"Mass-Training_P_00889_LEFT_MLO_1\",\n          \"Mass-Training_P_00148_RIGHT_MLO_1\",\n          \"Mass-Training_P_00199_LEFT_MLO_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROI_-1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1696,\n        \"samples\": [\n          \"Mass-Training_P_00889_LEFT_MLO_1\",\n          \"Mass-Training_P_00148_RIGHT_MLO_1\",\n          \"Mass-Training_P_00199_LEFT_MLO_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_-1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1592,\n        \"samples\": [\n          \"Mass-Training_P_01426_RIGHT_CC\",\n          \"Mass-Training_P_01803_RIGHT_CC\",\n          \"Mass-Test_P_01365_LEFT_CC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['crop_-1'] = merged_df['cropped image file path'].apply(lambda x: x.split('/')[0])\n",
        "merged_df['ROI_-1'] = merged_df['ROI mask file path'].apply(lambda x: x.split('/')[0])\n",
        "merged_df['full_-1'] = merged_df['image file path'].apply(lambda x: x.split('/')[0])"
      ],
      "metadata": {
        "id": "K0tGT_SDPPBD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if items in column1 and column2 of the same row are the same\n",
        "merged_df['same_items'] = merged_df['crop_-1'] == merged_df['ROI_-1']\n",
        "merged_df['full_same_items'] = merged_df['full_-1'].isin(merged_df['crop_-1'])\n",
        "\n",
        "#check if items in column A share the same pathology info or not when the items are same.\n",
        "merged_df['pathology_crop'] = merged_df['pathology'][merged_df['crop_-1'].duplicated(keep=False)].duplicated(keep=False)\n",
        "merged_df['pathology_roi'] = merged_df['pathology'][merged_df['ROI_-1'].duplicated(keep=False)].duplicated(keep=False)\n",
        "merged_df['pathology_full'] = merged_df['pathology'][merged_df['full_-1'].duplicated(keep=False)].duplicated(keep=False)\n",
        "\n",
        "# Count the number of False values\n",
        "count_false = (merged_df['same_items'] == False).sum()\n",
        "full_false = (merged_df['full_same_items'] == False).sum()\n",
        "pathology_crop = (merged_df['pathology_crop'] == False).sum()\n",
        "pathology_roi = (merged_df['pathology_roi'] == False).sum()\n",
        "pathology_full = (merged_df['pathology_full'] == False).sum()\n",
        "\n",
        "# Display the count\n",
        "print(\"Number of False values:\", count_false)\n",
        "print(\"Number of full_False values:\", count_false)\n",
        "print(\"Number of pathology crop:\", pathology_crop)\n",
        "print(\"Number of pathylogy roi:\", pathology_roi)\n",
        "print(\"Number of pathylogy full:\", pathology_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0kxobA0PrC4",
        "outputId": "e011a674-fc97-4bbc-fee6-4f4c38a8adeb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of False values: 0\n",
            "Number of full_False values: 0\n",
            "Number of pathology crop: 0\n",
            "Number of pathylogy roi: 0\n",
            "Number of pathylogy full: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have decided to use the Subject ID as a method to name the images and track the corresponding ROI and pathology. Please note that one full image may contain multiple ROIs. To avoid missing any of them, it is important to add different suffixes, prefixes, etc., while keeping the Subject ID the same before saving the converted version.\n",
        "Furthermore, to match ROIs to the corresponding full image, we will leverage the shared patient ID, left or right breast, and image view information. When the ROI and full image share these three pieces of information, we will match the ROI to the corresponding full image.\n",
        "Please note that one full image could have multiple ROIs."
      ],
      "metadata": {
        "id": "kC3UguW3_8wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##double check that the pathology is related to the Subject ID only for \"image file path\", \"ROI path\", and \"cropped path\"\n",
        "##here we put the code for for \"image file path\" only feel free to try others as well.\n",
        "\n",
        "# Identify duplicate 'image file path' values\n",
        "merged_df['name'] = merged_df['image file path'].str.split('/').str[0]\n",
        "is_duplicate = merged_df.duplicated(subset=['image file path'], keep='first')\n",
        "\n",
        "# Filter the DataFrame to keep only rows with unique 'image file path' values\n",
        "unique_df = merged_df[~is_duplicate]\n",
        "\n",
        "filtered_df = pd.DataFrame(columns=unique_df.columns)\n",
        "\n",
        "# Grouping by 'patient_id' and checking if 'pathology' values are the same within each group\n",
        "for name, group in unique_df.groupby('name'):\n",
        "    if len(group['pathology'].unique()) > 1:\n",
        "        print(\"Inconsistent pathology for name:\", name)\n",
        "        print(group)\n",
        "        unique_df = pd.concat([unique_df, group])\n",
        "\n",
        "# Resetting index for the filtered DataFrame\n",
        "filtered_df.reset_index(drop=True, inplace=True)\n",
        "print(len(filtered_df))"
      ],
      "metadata": {
        "id": "E80RSmsgEcky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30a3f34-f43a-4c4d-9be5-ca9f5067c7f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# convert dcm to png and save to a folder"
      ],
      "metadata": {
        "id": "HI8DO4Xh9iMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make sure the source and destination folder is ready\n",
        "#for full images, pixel_array = ds.pixel_array.astype('uint16').\n",
        "#for ROI and original cropped images(provided by CBIS-DDSM contributors),\n",
        "#pixel_array = ds.pixel_array.astype('uint8').\n",
        "\n",
        "def convert_dcm_to_png(source_folder, destination_root):\n",
        "\n",
        "    # Initialize a counter for failed conversions\n",
        "    failed_count = 0\n",
        "\n",
        "    # Initialize lists to store data for DataFrame\n",
        "    source_paths = []\n",
        "    png_paths = []\n",
        "    source_parts = []\n",
        "    png_parts = []\n",
        "\n",
        "    # Traverse through each item in the source folder\n",
        "    for item in os.listdir(source_folder):\n",
        "        source_item_path = os.path.join(source_folder, item)\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(source_item_path):\n",
        "            # Recursively convert .dcm files in subdirectories\n",
        "            sub_failed_count, sub_df = convert_dcm_to_png(source_item_path, destination_root)\n",
        "            failed_count += sub_failed_count\n",
        "            source_paths.extend(sub_df['source_path'])\n",
        "            png_paths.extend(sub_df['png_path'])\n",
        "            source_parts.extend(sub_df['source_part'])\n",
        "            png_parts.extend(sub_df['png_part'])\n",
        "\n",
        "        elif item.endswith('.dcm'):\n",
        "            try:\n",
        "                # Read DICOM file\n",
        "                ds = pydicom.dcmread(source_item_path, force=True)\n",
        "\n",
        "                # Convert pixel data to unit 16 or uint8\n",
        "                # pixel_array = ds.pixel_array.astype('uint16') #for full image\n",
        "                pixel_array = ds.pixel_array.astype('uint8') # for ROI and croped image\n",
        "\n",
        "                # Create an 8-bit image from the array\n",
        "                image = Image.fromarray(pixel_array)\n",
        "\n",
        "                # Extract the filename without extension\n",
        "                name = os.path.splitext(os.path.basename(source_item_path))[0]\n",
        "\n",
        "                # Extract the last 4 parts of the path\n",
        "                source_part = source_item_path.split('/')[-4]\n",
        "\n",
        "                # Construct the destination folder path\n",
        "                destination_folder = os.path.join(destination_root, source_part)\n",
        "\n",
        "                # Create destination folder if it doesn't exist\n",
        "                os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "                # Construct the destination PNG file path\n",
        "                png_path = os.path.join(destination_folder, f\"_{name}.png\")\n",
        "\n",
        "                # Check if the PNG file already exists\n",
        "                while os.path.exists(png_path):\n",
        "                    # Add a prefix \"_\" before the name\n",
        "                    name = f\"_{name}\"\n",
        "                    png_path = os.path.join(destination_folder, f\"_{name}.png\")\n",
        "\n",
        "                # Save as PNG directly in the destination folder\n",
        "                image.save(png_path, format='PNG')\n",
        "\n",
        "                # Append paths and parts to lists\n",
        "                source_paths.append(source_item_path)\n",
        "                png_paths.append(png_path)\n",
        "                source_parts.append(source_part)\n",
        "                png_parts.append(png_path.split('/')[-2])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to convert {source_item_path}: {e}\")\n",
        "                failed_count += 1\n",
        "\n",
        "    # Return the total number of failed conversions and DataFrame\n",
        "    return failed_count, pd.DataFrame({\n",
        "        'source_path': source_paths,\n",
        "        'png_path': png_paths,\n",
        "        'source_part': source_parts,\n",
        "        'png_part': png_parts\n",
        "    })\n",
        "\n",
        "# Specify the source folder and destination root\n",
        "source_folder = \"/content/mass_train_ROI/manifest-LyDgOQGl3853937313152078328/CBIS-DDSM\"\n",
        "!mkdir /content/roi_train\n",
        "destination_root = \"/content/roi_train\"\n",
        "\n",
        "# Convert DICOM files to PNG and get the total number of failed conversions and DataFrame\n",
        "full_failed, full_df = convert_dcm_to_png(source_folder, destination_root)"
      ],
      "metadata": {
        "id": "NNwWGY4Qs9lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check how many images under the root folder\n",
        "# Specify the root folder\n",
        "root_folder = \"/content/roi_train\"\n",
        "\n",
        "# Initialize a dictionary to store unique base names and their counts\n",
        "unique_base_names_counts = {}\n",
        "\n",
        "# Iterate through the files in the root folder\n",
        "for folder, _, files in os.walk(root_folder):\n",
        "    for file in files:\n",
        "        # Check if the file ends with \".png\"\n",
        "        if file.endswith(\".png\"): #could be .dcm, .png, or other format as the user's preference\n",
        "            # Extract the base name without extension\n",
        "            base_name = os.path.splitext(file)[0]\n",
        "            # Update the count for the base name in the dictionary\n",
        "            unique_base_names_counts[base_name] = unique_base_names_counts.get(base_name, 0) + 1\n",
        "\n",
        "# Count the number of unique base names\n",
        "num_unique_base_names = len(unique_base_names_counts)\n",
        "\n",
        "# Print the number of unique base names\n",
        "print(f\"Number of unique base names of images ending with '.png': {num_unique_base_names}\")\n",
        "\n",
        "# Print the unique base names and their total counts\n",
        "print(\"Unique base names of images ending with '.png' and their total counts:\")\n",
        "for base_name, count in unique_base_names_counts.items():\n",
        "    print(f\"{base_name}: {count}\")"
      ],
      "metadata": {
        "id": "FpHm0ujZScsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#move converted png images to one folder\n",
        "def move_images(root_dir, dest_dir):\n",
        "    # Walk through the directory structure\n",
        "    for foldername, _, filenames in os.walk(root_dir):\n",
        "        # Iterate over each file in the current directory\n",
        "        for filename in filenames:\n",
        "            # Construct the source and destination paths\n",
        "            source_path = os.path.join(foldername, filename)\n",
        "            dest_path = os.path.join(dest_dir, foldername.replace('/', '_') + '_' + filename)\n",
        "\n",
        "            # Create destination directory if it doesn't exist\n",
        "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "\n",
        "            # Move the file\n",
        "            shutil.move(source_path, dest_path)\n",
        "            print(f\"Moved: {source_path} -> {dest_path}\")\n",
        "\n",
        "# Specify the root directory containing images\n",
        "root_dir = \"/content/roi_train\"\n",
        "\n",
        "!mkdir /content/roi_train_needed\n",
        "# Specify the destination directory\n",
        "dest_dir = \"/content/roi_train_needed\"\n",
        "\n",
        "# Call the function to move images\n",
        "move_images(root_dir, dest_dir)\n"
      ],
      "metadata": {
        "id": "hLUfT3OPYVP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run the previously codes multiple times with different root and destination folders to convert all mass full images and ROIs to PNG format.\n",
        "\n",
        "To make it easier to identify and remove the converted cropped images:\n",
        "\n",
        "Download the converted ROIs and cropped images.\n",
        "Sort the images by size; most of the cropped images should have a larger size and contain only black and white dots.\n",
        "Manually remove the identified images."
      ],
      "metadata": {
        "id": "Xbr6yni7BpWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the mismatched ROI and full images"
      ],
      "metadata": {
        "id": "XLmRbj2O9aGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that the PNG format full images and ROI images are ready."
      ],
      "metadata": {
        "id": "UzYQ-YxXC7g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_names_from_folder(folder_path):\n",
        "    # Get the list of files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Define a regular expression pattern to match the desired parts of the filename\n",
        "    # pattern = re.compile(r\"Mass-(.*?)_1(.*?)\\.png\")\n",
        "    pattern = re.compile(r\"Mass-(.*?)_(MLO|CC)(.*?)\\.png\")\n",
        "    # Create a list to store the extracted data\n",
        "    extracted_data = []\n",
        "\n",
        "    # Iterate over the files and extract the data\n",
        "    for filename in files:\n",
        "        match = pattern.search(filename)\n",
        "        if match:\n",
        "            # extract the content\n",
        "            name = f\"Mass-{match.group(1)}_{match.group(2)}\"\n",
        "            last_number = re.findall(r'\\d+', match.group(3))[-1]\n",
        "            extracted_data.append({\n",
        "                'name': name,\n",
        "                '1or2': last_number,\n",
        "                'path': os.path.join(folder_path, filename)\n",
        "            })\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "# Specify the paths of the two folders to compare\n",
        "folder1_path = \"/content/roi_train_needed\"\n",
        "folder2_path = \"/content/full_train_needed\"\n",
        "\n",
        "# Extract data from both folders\n",
        "data_in_folder1 = extract_names_from_folder(folder1_path)\n",
        "data_in_folder2 = extract_names_from_folder(folder2_path)\n",
        "\n",
        "# Convert the lists to pandas DataFrames\n",
        "df_folder1 = pd.DataFrame(data_in_folder1)\n",
        "df_folder2 = pd.DataFrame(data_in_folder2)"
      ],
      "metadata": {
        "id": "-KSTNfeeaUW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the DataFrames on the 'name' column to find common names\n",
        "common_data_df = pd.merge(df_folder1, df_folder2, on='name', suffixes=('_ROI', '_Full'), how='left')"
      ],
      "metadata": {
        "id": "8IMH4VBj0JnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !find /content/roi -type f -name \"*.png\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14hSJ3I9gUWO",
        "outputId": "32d0bd5d-2dca-4326-8712-b6ed61dded9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# common_data_df DataFrame with columns 'path_ROI', 'path_Full', and 'name'\n",
        "\n",
        "mismated_info = []  # List to store information about mismated images\n",
        "\n",
        "for index, row in common_data_df.iterrows():\n",
        "    roi_path = row['path_ROI']\n",
        "    full_path = row['path_Full']\n",
        "    name = row['path_ROI'].split('/')[-1]\n",
        "    name = name.replace(\"_content_mass_test_failed_\", \"\")\n",
        "\n",
        "    # Open ROI and full images\n",
        "    roi_image = Image.open(roi_path)\n",
        "    full_image = Image.open(full_path)\n",
        "\n",
        "    # Resize the roi image to meet the full image size\n",
        "    if roi_image.size != full_image.size:\n",
        "        mismated_info.append((name, full_image.size, roi_image.size))  # Save mismated image info\n",
        "        print(f\"Found one difference in sizes for {name}.\")\n",
        "\n",
        "print(\"All images successfully processed.\")\n",
        "\n",
        "# Save mismated images information to CSV\n",
        "if mismated_info:\n",
        "    df_mismated = pd.DataFrame(mismated_info, columns=['Image Name', 'Full Image Size', 'ROI Size'])\n",
        "    df_mismated.to_csv('mismated_image_info.csv', index=False) #save the mismatched info to your desirved folder\n",
        "    print(\"Mismated images information saved to mismated_images_info.csv.\")\n",
        "else:\n",
        "    print(\"No mismated images found.\")"
      ],
      "metadata": {
        "id": "g5l_p-2Ldhsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# map ROI to the original image"
      ],
      "metadata": {
        "id": "vokenaMuh9Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in common_data_df.iterrows():\n",
        "    roi_path = row['path_ROI']\n",
        "    full_path = row['path_Full']\n",
        "    name = row['path_ROI'].split('/')[-1]\n",
        "    name = name.replace(\"_content_mass_test_failed_\", \"\")\n",
        "\n",
        "    # Open ROI and full images\n",
        "    roi_image = Image.open(roi_path)\n",
        "    full_image = Image.open(full_path)\n",
        "\n",
        "    # Convert ROI image to RGBA\n",
        "    roi_image = roi_image.convert(\"RGBA\")\n",
        "    datas = roi_image.getdata()\n",
        "    new_data = []\n",
        "\n",
        "    for i in range(len(datas)):\n",
        "        item = datas[i]\n",
        "        # If pixel's grayscale value is greater than 125, set it to transparent\n",
        "        if item[0] == 255:\n",
        "            new_data.append((255, 255, 255, 0))  # Set white pixels to transparent\n",
        "        else:\n",
        "            new_data.append(item)\n",
        "\n",
        "    roi_image.putdata(new_data)\n",
        "\n",
        "    # Resize the roi image to meet the full image size\n",
        "    if roi_image.size != full_image.size:\n",
        "        mask_size = full_image.size\n",
        "        roi_image = roi_image.resize(mask_size)\n",
        "        print(f\"found one difference sizes {name} \")\n",
        "    else:\n",
        "        mask_size = full_image.size\n",
        "\n",
        "    # set the mask position\n",
        "    mask_position = (0, 0)  # Top-left corner\n",
        "\n",
        "    # map ROI to the full image\n",
        "    full_image.paste(roi_image, mask_position, roi_image)\n",
        "\n",
        "    # Prepare the save path with the corresponding number of underscores\n",
        "    save_path = f\"/content/train_same_size/{name}\"\n",
        "\n",
        "    # Save the processed full image\n",
        "    full_image.save(save_path)\n",
        "    # print(f\"Mapped image {name} saved.\")\n",
        "\n",
        "    # Print the number of images generated for each iteration\n",
        "    # print(f\"Image {name} saved.\")\n",
        "print(\"All images successfully processed\")"
      ],
      "metadata": {
        "id": "3ED8qJJIEm35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract 598 by 598 pixel"
      ],
      "metadata": {
        "id": "6x02iqNB4S7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure the mapped images are ready"
      ],
      "metadata": {
        "id": "h3Ftnh_YF8wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nonzero_center(img):\n",
        "    # get the width and height from the image size\n",
        "    width, height = img.size\n",
        "\n",
        "    # Initialize the total pixel count and cumulative values of two coordinates\n",
        "    total_pixels = 0\n",
        "    sum_x = 0\n",
        "    sum_y = 0\n",
        "\n",
        "    # iterate and calculate the values\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            pixel_value = img.getpixel((x, y))\n",
        "            if pixel_value != 0:\n",
        "                total_pixels += 1\n",
        "                sum_x += x\n",
        "                sum_y += y\n",
        "\n",
        "    # Calculate the geometric center coordinates of non-zero pixels\n",
        "    center_x = sum_x // total_pixels if total_pixels > 0 else width // 2\n",
        "    center_y = sum_y // total_pixels if total_pixels > 0 else height // 2\n",
        "\n",
        "    return (center_x, center_y)\n",
        "\n",
        "def extract_center_for_folder(input_folder, output_folder, output_size):\n",
        "    # create the output_folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # iterate all images\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".png\"):\n",
        "            # Construct input and output file paths\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "            # open the image\n",
        "            img = Image.open(input_path)\n",
        "\n",
        "            # Find the geometric center coordinates of non-zero pixels\n",
        "            center_x, center_y = find_nonzero_center(img)\n",
        "\n",
        "            # Calculate the coordinates of the top-left and bottom-right corners of the cropping area\n",
        "            left = max(0, center_x - output_size // 2)\n",
        "            top = max(0, center_y - output_size // 2)\n",
        "            right = min(center_x + output_size // 2, img.width)\n",
        "            bottom = min(center_y + output_size // 2, img.height)\n",
        "\n",
        "            # crop the image\n",
        "            cropped_img = img.crop((left, top, right, bottom))\n",
        "\n",
        "            # save the cropped image\n",
        "            cropped_img.save(output_path)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Invoke the function to process images in a specified folder\n",
        "extract_center_for_folder(\"/content/train_same_size\", \"/content/train_598\", 598)"
      ],
      "metadata": {
        "id": "uev7fXEj6kKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Image process finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P6qmgoXTJWl",
        "outputId": "7caa698c-7926-447f-c142-49ce021080b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image process finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# review examples which have clear white edge in mapped images"
      ],
      "metadata": {
        "id": "ukuB10kWJQSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#we went back and converted the suspecious original .dcm images and double checked that them contain white edges\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source folders and destination folder\n",
        "source_folders = \"/content/mass_train/CBIS-DDSM\"\n",
        "destination_folder = \"/content/test\"\n",
        "\n",
        "# Define example keywords to search for in file names\n",
        "keywords = [\"Mass-Training_P_00110_LEFT_CC\",\n",
        "            \"Mass-Training_P_00708_RIGHT_CC\",\n",
        "            \"Mass-Training_P_01493_RIGHT_CC\"]\n",
        "\n",
        "# Iterate through each source folder\n",
        "for source_folder in source_folders:\n",
        "    # Iterate through each root, dirs, and files in the source folder recursively\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        # Check if any of the keywords are in the root folder name\n",
        "        if any(keyword in root for keyword in keywords):\n",
        "            # Iterate through files in the current root\n",
        "            for file in files:\n",
        "                # Check if the file ends with .dcm\n",
        "                if file.endswith(\".dcm\"):\n",
        "                    # Construct the new file name using the keyword\n",
        "                    keyword_name = next((keyword for keyword in keywords if keyword in root), None)\n",
        "                    if keyword_name:\n",
        "                        new_file_name = f\"{keyword_name}.dcm\"\n",
        "                    else:\n",
        "                        new_file_name = file\n",
        "\n",
        "                    # Copy the file to the destination folder with the new name\n",
        "                    source_path = os.path.join(root, file)\n",
        "                    destination_path = os.path.join(destination_folder, new_file_name)\n",
        "                    shutil.copyfile(source_path, destination_path)\n",
        "                    print(f\"File '{file}' copied and saved as '{new_file_name}' in '{destination_folder}'\")\n",
        "\n",
        "print(\"All .dcm files copied and saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXl82-K5G3Hq",
        "outputId": "0d0c8844-f3b9-4bda-f271-c72ffe608482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File '1-1.dcm' copied and saved as 'Mass-Training_P_01493_RIGHT_CC.dcm' in '/content/test'\n",
            "File '1-1.dcm' copied and saved as 'Mass-Training_P_00708_RIGHT_CC.dcm' in '/content/test'\n",
            "File '1-1.dcm' copied and saved as 'Mass-Training_P_00110_LEFT_CC.dcm' in '/content/test'\n",
            "All .dcm files copied and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#since the selected exmaple .dcm filse is unable to view, we converted them to .png for visualization\n",
        "###\n",
        "\n",
        "import os\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "\n",
        "# Define source folder containing .dcm files and destination folder for .png files\n",
        "source_folder = \"/content/test\"\n",
        "!mkdir /content/test_\n",
        "destination_folder = \"/content/test_\"\n",
        "\n",
        "# Iterate through each .dcm file in the source folder\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.endswith(\".dcm\"):\n",
        "        # Load the DICOM file\n",
        "        dcm_path = os.path.join(source_folder, filename)\n",
        "        dcm_data = pydicom.dcmread(dcm_path)\n",
        "\n",
        "        # Convert DICOM to PIL Image\n",
        "        image = Image.fromarray(dcm_data.pixel_array)\n",
        "\n",
        "        # Save the PIL Image as PNG with the same name\n",
        "        png_path = os.path.join(destination_folder, os.path.splitext(filename)[0] + \".png\")\n",
        "        image.save(png_path)\n",
        "\n",
        "        print(f\"Converted '{filename}' to '{png_path}'\")\n",
        "\n",
        "print(\"Conversion completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtYzD7MSInr6",
        "outputId": "81bbda16-c4ac-4c53-9169-3625fcaa1f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 'Mass-Training_P_01493_RIGHT_CC.dcm' to '/content/test_/Mass-Training_P_01493_RIGHT_CC.png'\n",
            "Converted 'Mass-Training_P_00708_RIGHT_CC.dcm' to '/content/test_/Mass-Training_P_00708_RIGHT_CC.png'\n",
            "Converted 'Mass-Training_P_00110_LEFT_CC.dcm' to '/content/test_/Mass-Training_P_00110_LEFT_CC.png'\n",
            "Conversion completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###find corresponding roi images and converted full image in png format as well.\n",
        "##############\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source folders and destination folder\n",
        "source_folders = [\"/content/roi_crop_train/roi_train_needed\", \"/content/full_train_needed\"]\n",
        "!mkdir /content/review\n",
        "destination_folder = \"/content/review\"\n",
        "\n",
        "# Define keywords to search for in file names\n",
        "keywords = [\"train_Mass-Training_P_00110_LEFT_CC\",\n",
        "            \"train_Mass-Training_P_00708_RIGHT_CC\",\n",
        "            \"train_Mass-Training_P_01493_RIGHT_CC\"]\n",
        "\n",
        "# Iterate through each source folder\n",
        "for source_folder in source_folders:\n",
        "    # Get the list of files in the source folder\n",
        "    files = os.listdir(source_folder)\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        # Check if the file name contains any of the keywords\n",
        "        if any(keyword in file for keyword in keywords):\n",
        "            # Construct the source and destination paths\n",
        "            source_path = os.path.join(source_folder, file)\n",
        "            destination_path = os.path.join(destination_folder, file)\n",
        "\n",
        "            # Copy the file to the destination folder\n",
        "            shutil.copyfile(source_path, destination_path)\n",
        "            print(f\"File '{file}' copied to '{destination_folder}'\")\n",
        "\n",
        "print(\"All files copied successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AYmsbKACCEu",
        "outputId": "9670fc90-f128-4f82-f46f-32e84eb8a512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File '_content_roi_train_Mass-Training_P_00110_LEFT_CC_1__1-2.png' copied to '/content/review'\n",
            "File '_content_roi_train_Mass-Training_P_00708_RIGHT_CC_1__1-1.png' copied to '/content/review'\n",
            "File '_content_roi_train_Mass-Training_P_01493_RIGHT_CC_1__1-1.png' copied to '/content/review'\n",
            "File '_content_full_train_Mass-Training_P_00708_RIGHT_CC__1-1.png' copied to '/content/review'\n",
            "File '_content_full_train_Mass-Training_P_01493_RIGHT_CC__1-1.png' copied to '/content/review'\n",
            "File '_content_full_train_Mass-Training_P_00110_LEFT_CC__1-1.png' copied to '/content/review'\n",
            "All files copied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate transparent images of ROI\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to process images\n",
        "def process_image(input_path, output_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(input_path)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Canny edge detection\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a blank image with transparency\n",
        "    output = np.zeros_like(image, dtype=np.uint8)\n",
        "\n",
        "    # Fill contours with green color\n",
        "    cv2.drawContours(output, contours, -1, (0, 255, 0), thickness=3)\n",
        "\n",
        "    # Set black parts as transparent\n",
        "    output = cv2.cvtColor(output, cv2.COLOR_BGR2BGRA)\n",
        "    output[..., 3] = np.where((output[..., :3] == [0, 0, 0]).all(axis=2), 0, 255)\n",
        "\n",
        "    # Save the processed image\n",
        "    cv2.imwrite(output_path, output)\n",
        "    print(f\"Processed {input_path} and saved to {output_path}\")\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = '/content/roi_crop_train/roi_train_needed'\n",
        "!mkdir /content/full_trainsparent\n",
        "output_folder = '/content/train_roi_transparent'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Process each image in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.png') or filename.endswith('.jpg'):  # Adjust file extensions as needed\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        process_image(input_path, output_path)\n",
        "\n",
        "print(\"All images processed and saved successfully.\")\n"
      ],
      "metadata": {
        "id": "QhgYUm9xVtDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compare and ensure that the white edge is pure background."
      ],
      "metadata": {
        "id": "9qvzMIXFGiLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# take care white edge"
      ],
      "metadata": {
        "id": "9O7gHjnI0kCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ensure the extracted images which contain unwanted white edges are ready."
      ],
      "metadata": {
        "id": "IgEy0cJvGqcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/white edge.zip\""
      ],
      "metadata": {
        "id": "sEqUeimF0mnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the source and destinaation folder\n",
        "source_folder = '/content/white edge'\n",
        "destination_folder = '/content/adjusted/'\n",
        "\n",
        "# create the destination folder if not existed\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# iterate all images inside a folder\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.endswith('.png'):\n",
        "        file_path = os.path.join(source_folder, filename)\n",
        "\n",
        "        img = Image.open(file_path)\n",
        "\n",
        "        width, height = img.size\n",
        "\n",
        "        for x in range(width):\n",
        "            for y in range(height):\n",
        "                pixel_value = img.getpixel((x, y))\n",
        "\n",
        "                if pixel_value == 65535:  #we only removed the pure white part, the pixel value = 65535\n",
        "                    img.putpixel((x, y), 0)\n",
        "\n",
        "        destination_filename = filename.replace('_content_', 'adjusted_')\n",
        "\n",
        "        destination_file_path = os.path.join(destination_folder, destination_filename)\n",
        "\n",
        "        img.save(destination_file_path)\n",
        "\n",
        "print(\"All images processed and saved in the destination folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWpUoOi32EEQ",
        "outputId": "ae4cddc2-c8fa-45d8-c132-6335bbc9ff40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed and saved in the destination folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# size adjustment: 598 by 598"
      ],
      "metadata": {
        "id": "QOdU3cXzi84k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_and_save_image(image_path, target_size=(598, 598), save_dir='same_images', adjusted_dir='adjusted'):\n",
        "    # create the destination folder\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    os.makedirs(adjusted_dir, exist_ok=True)\n",
        "\n",
        "    # open the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # get the width and height\n",
        "    width, height = image.size\n",
        "\n",
        "    # if the size doesn't match witht he target size\n",
        "    if width != target_size[0] or height != target_size[1]:\n",
        "        # calculate the size we need to add\n",
        "        left = (target_size[0] - width) // 2\n",
        "        top = (target_size[1] - height) // 2\n",
        "        right = target_size[0] - width - left\n",
        "        bottom = target_size[1] - height - top\n",
        "\n",
        "        # Create a new image and paste the 'image' onto it\n",
        "        new_image = Image.new(image.mode, target_size, 0)  # fill in with black color\n",
        "        new_image.paste(image, (left, top))\n",
        "\n",
        "        # Save the adjusted image to the corresponding directory\n",
        "        adjusted_path = os.path.join(adjusted_dir, os.path.basename(image_path))\n",
        "        new_image.save(adjusted_path)\n",
        "    else:\n",
        "        # Directly copy images of equal dimensions to a new folder\n",
        "        save_path = os.path.join(save_dir, os.path.basename(image_path))\n",
        "        image.save(save_path)\n",
        "\n",
        "# input folder\n",
        "image_folder = '/content/train_598'\n",
        "\n",
        "# save the size updated images\n",
        "adjusted_folder = '/content/train_598_updated'\n",
        "\n",
        "# save the original images\n",
        "same_folder = '/content/train_598_same'\n",
        "\n",
        "# iterate all images in the input folder\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        adjust_and_save_image(image_path, save_dir=same_folder, adjusted_dir=adjusted_folder)"
      ],
      "metadata": {
        "id": "yx7ooreJjAxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_image_size(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".png\"):  # Check only PNG files, adjust if needed\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path)\n",
        "            width, height = image.size\n",
        "            if width != 598 or height != 598:\n",
        "                print(f\"Image '{filename}' has size {width}x{height} pixels.\")\n",
        "\n",
        "# Replace 'path_to_folder' with the actual path to your folder containing images\n",
        "check_image_size('/content/train_598_same')\n",
        "check_image_size('/content/train_598_updated')\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnYAIRc-GPDG",
        "outputId": "d78023fc-b8ef-4de9-d925-1082d28b84b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data augmentation"
      ],
      "metadata": {
        "id": "yUoXoNTNi51s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# input folder\n",
        "folder_path = '/content/all_598'\n",
        "\n",
        "# get the file path of the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# check the amount of files, by the way\n",
        "num_images = len(file_list)\n",
        "\n",
        "print(f\"There are {num_images} images in the folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIrzGxBZ4GOG",
        "outputId": "8c67d3d3-aaec-424b-8616-77194fbc0cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1696 images in the folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define the directory containing the original images\n",
        "original_dir = '/content/all_598'\n",
        "\n",
        "# Define the directory to save the augmented images\n",
        "augmented_dir = '/content/all_598_augmented'\n",
        "\n",
        "# Ensure the augmented directory exists, create if not\n",
        "if not os.path.exists(augmented_dir):\n",
        "    os.makedirs(augmented_dir)\n",
        "\n",
        "# ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# List all original image files\n",
        "original_files = os.listdir(original_dir)\n",
        "\n",
        "# Function to save augmented images\n",
        "def save_augmented_images(img, prefix, idx):\n",
        "    filename = os.path.join(augmented_dir, f\"{prefix}_{idx}.png\")\n",
        "    cv2.imwrite(filename, img)\n",
        "\n",
        "# Iterate through each original image\n",
        "for filename in original_files:\n",
        "    # Load the original image\n",
        "    img = cv2.imread(os.path.join(original_dir, filename), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    # Reshape to add a channel dimension if it's missing\n",
        "    if len(img.shape) == 2:\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "    # Rescale to [0, 1]\n",
        "    img = img.astype(np.float32) / 65535.0\n",
        "\n",
        "    # Reshape to 4D array (batch_size, rows, columns, channels) for augmentation\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Generate augmented images\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1):\n",
        "        augmented_img = (batch[0] * 65535).astype(np.uint16)  # Rescale back to 16-bit\n",
        "        save_augmented_images(augmented_img,os.path.splitext(filename)[0], i + 1)\n",
        "        print(f\"Augmented image {i + 1} saved to : {filename}\")\n",
        "        i += 1\n",
        "        if i >= 5:  # Generate 5 augmented images for each original image\n",
        "            break\n",
        "print(\"Data augmentation completed.\")"
      ],
      "metadata": {
        "id": "9oVyWWwwi72M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#move the input to the output\n",
        "!mv /content/all_598/* /content/all_598_augmented/"
      ],
      "metadata": {
        "id": "I1_qSh6TpQPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# input folder\n",
        "folder_path = '/content/all_598_augmented'\n",
        "\n",
        "# image name\n",
        "files_list = os.listdir(folder_path)\n",
        "\n",
        "# check if it is unique\n",
        "unique_paths = len(set(files_list)) == len(files_list)\n",
        "\n",
        "# calculate the image size\n",
        "total_files = len(files_list)\n",
        "\n",
        "print(f\"Are all paths unique? {unique_paths}\")\n",
        "print(f\"Total amount of files: {total_files}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjA44LhRpKbv",
        "outputId": "69195945-6b88-461e-f822-97d2777923d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are all paths unique? True\n",
            "Total amount of files: 10176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/CBIS-DDSM/all_598_augmented_mode.zip /content/all_598_augmented"
      ],
      "metadata": {
        "id": "Yo277mhipUoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# merge train and test descirption csv files"
      ],
      "metadata": {
        "id": "xRUxafgrj02-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/CBIS-DDSM/mass_case_description_train_set.csv')\n",
        "\n",
        "test = pd.read_csv('/content/drive/MyDrive/CBIS-DDSM/mass_case_description_test_set.csv')"
      ],
      "metadata": {
        "id": "1s37lUeBddQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_need = train[['patient_id', 'pathology', 'image file path', 'cropped image file path', 'ROI mask file path']]\n",
        "test_need = test[['patient_id', 'pathology', 'image file path', 'cropped image file path','ROI mask file path']]"
      ],
      "metadata": {
        "id": "v62kP1ZudjXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([train_need, test_need], axis=0)"
      ],
      "metadata": {
        "id": "kAkuyMgBdjXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "p04b26gUdjXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['crop_name'] = merged_df['cropped image file path'].apply(lambda x: x.split('/')[0])\n",
        "merged_df['ROI_name'] = merged_df['ROI mask file path'].apply(lambda x: x.split('/')[0])\n",
        "merged_df['full_name'] = merged_df['image file path'].apply(lambda x: x.split('/')[0])"
      ],
      "metadata": {
        "id": "defJroWk3B-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['ROI number'] = merged_df['ROI mask file path'].apply(lambda x: re.findall(r'\\d+(?=.dcm)', x)[-1][-1] if re.findall(r'\\d+(?=.dcm)', x) else None)\n",
        "merged_df['Crop number'] = merged_df['cropped image file path'].apply(lambda x: re.findall(r'\\d+(?=.dcm)', x)[-1][-1] if re.findall(r'\\d+(?=.dcm)', x) else None)"
      ],
      "metadata": {
        "id": "YIBflGNuxYJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['ROI number'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VOPlyxo3sCx",
        "outputId": "475c4cca-b536-44da-ee4f-428a3548a038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1593\n",
              "0     103\n",
              "Name: ROI number, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('all_mass_pathology.csv', index=False)"
      ],
      "metadata": {
        "id": "dBCJrGIB2dRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# calculate the non-0 area and full image size"
      ],
      "metadata": {
        "id": "gk8LwU7JGmJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate cropped area per 598 by 598.\n",
        "\n",
        "calculate full images size."
      ],
      "metadata": {
        "id": "58e3pBaLG87b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for non-zero area calculation\n",
        "def process_image_and_extract_groups(image_path):\n",
        "    # Define the regex pattern\n",
        "    pattern = r'Mass-Training_P_(\\d+)_(\\w+)_(\\w+)_' #for training dataset, make sure you pick the proper one\n",
        "    pattern = r'Mass-Test_P_(\\d+)_(\\w+)_(\\w+)_' #for training dataset, make sure you pick the proper one\n",
        "\n",
        "\n",
        "    match = re.search(pattern, image_path)\n",
        "    if match:\n",
        "        number = match.group(1)\n",
        "        left = match.group(2)\n",
        "        cc = match.group(3)\n",
        "        result = f'Mass-Test_P_{number}_{left}_{cc}'\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Convert the grayscale image to a NumPy array\n",
        "        image_array = np.array(image)\n",
        "\n",
        "        # Calculate the non-zero area\n",
        "        nonzero_pixels = np.count_nonzero(image_array)\n",
        "        total_pixels = image_array.size\n",
        "        nonzero_area_percentage = (nonzero_pixels / total_pixels) * 100\n",
        "\n",
        "        return result, image, nonzero_area_percentage\n",
        "    else:\n",
        "        print(f\"No match found for file: {image_path}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df_test = pd.DataFrame(columns=['name', 'file_path', 'area_percentage'])\n",
        "\n",
        "# Replace 'path_to_folder' with the actual path to your folder containing images\n",
        "folder_path = '/content/test_598_same'\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".png\"):  # Check only PNG files, adjust if needed\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        results, image, nonzero_area_percentage = process_image_and_extract_groups(image_path)\n",
        "        if results and image and nonzero_area_percentage:\n",
        "            df_test = df_test.append({'name': results, 'file_path': image_path, 'area_percentage': nonzero_area_percentage}, ignore_index=True)\n",
        "\n",
        "# Save the df\n",
        "# df.to_csv('output.csv', index=False)\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "id": "uIyrmn60G3VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the DataFrames using pd.concat()\n",
        "merged_df = pd.concat([df, df_test])\n",
        "sorted_merged_df = merged_df.sort_values(by='name')\n",
        "sorted_merged_df = sorted_merged_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "G_PrCpr9ReIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add the pathology information to the output as well\n",
        "pathology = pd.read_csv('/content/content/all_mass_pathology.csv')\n",
        "sorted_pathology = pathology.sort_values(by='full_name')\n",
        "sorted_pathology = sorted_pathology.reset_index(drop=True)\n",
        "# creat a column pathology in sorted_merged_df\n",
        "sorted_merged_df['pathology'] = None\n",
        "\n",
        "# copy the pathology if meet the requirement\n",
        "def copy_pathology(row):\n",
        "    for name in sorted_pathology['full_name']:\n",
        "        if name in row['name']:\n",
        "            return sorted_pathology.loc[sorted_pathology['full_name'] == name, 'pathology'].values[0]\n",
        "    return None\n",
        "\n",
        "sorted_merged_df['pathology'] = sorted_merged_df.apply(copy_pathology, axis=1)"
      ],
      "metadata": {
        "id": "9ODefXbba8Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the output\n",
        "sorted_merged_df.to_csv('/content/content/598_percentage_all.csv')"
      ],
      "metadata": {
        "id": "AXw9bf3rJFIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensure all full images are ready at hand\n",
        "#####\n",
        "#put all full images in side the folder /content/full_train_needed\n",
        "#####\n",
        "\n",
        "# Folder containing the images\n",
        "folder_path = '/content/content/full_train_needed'\n",
        "\n",
        "# Initialize lists to store image path, width, and height information\n",
        "image_path_list = []\n",
        "width_list = []\n",
        "height_list = []\n",
        "\n",
        "# Loop through each file in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.png'):  # Check if the file is a PNG image\n",
        "        # Construct the full path to the image\n",
        "        image_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Extract the part between 'full_' and '.png' in the filename\n",
        "        image_name = file_name.split('full_')[1].split('.png')[0]\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Get width and height\n",
        "        width, height = image.size\n",
        "\n",
        "        # Append image path, width, and height to lists\n",
        "        image_path_list.append(image_name)\n",
        "        width_list.append(width)\n",
        "        height_list.append(height)\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "data = {'Subject_ID': image_path_list, 'Width': width_list, 'Height': height_list}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "# df.to_csv('image_pixel.csv', index=False)"
      ],
      "metadata": {
        "id": "F4dpylDtGUs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat a column pathology in df\n",
        "df['pathology'] = None\n",
        "\n",
        "# copy the pathology if meet the requirement\n",
        "def copy_pathology(row):\n",
        "    for name in sorted_pathology['full_name']:\n",
        "        if name in row['Subject_ID']:\n",
        "            return sorted_pathology.loc[sorted_pathology['full_name'] == name, 'pathology'].values[0]\n",
        "    return None\n",
        "\n",
        "df['pathology'] = df.apply(copy_pathology, axis=1)"
      ],
      "metadata": {
        "id": "Bjlgg1PHkdhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sort = df.sort_values(by='Subject_ID')"
      ],
      "metadata": {
        "id": "owTdBfrSlUkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sort.to_csv('/content/metadata/heaght_width_FULL.csv')"
      ],
      "metadata": {
        "id": "tVksBBCnkoZu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Kxjh2cPw-l1a",
        "0VvN39brdKF1",
        "HI8DO4Xh9iMX",
        "XLmRbj2O9aGB",
        "vokenaMuh9Rs",
        "6x02iqNB4S7I",
        "ukuB10kWJQSx",
        "9O7gHjnI0kCe",
        "QOdU3cXzi84k",
        "yUoXoNTNi51s",
        "xRUxafgrj02-",
        "gk8LwU7JGmJ5"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}